{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from xvfbwrapper import Xvfb\n",
    "\n",
    "#vdisplay = Xvfb()\n",
    "#vdisplay.start()\n",
    "\n",
    "# for environ\n",
    "import os\n",
    "\n",
    "# only using device 0\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "#os.environ[\"LIBGL_ALWAYS_SOFTWARE\"]=\"1\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "# importing tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# import scipy\n",
    "import scipy, csv\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "import cvxpy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import wrappers\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# to display environment data\n",
    "# see https://gist.github.com/thomelane/79e97630ba46c45985a946cae4805885\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '/localhome/volodin/miniconda3/envs/neuronfailure/lib/python36.zip',\n",
       " '/localhome/volodin/miniconda3/envs/neuronfailure/lib/python3.6',\n",
       " '/localhome/volodin/miniconda3/envs/neuronfailure/lib/python3.6/lib-dynload',\n",
       " '/localhome/volodin/miniconda3/envs/neuronfailure/lib/python3.6/site-packages',\n",
       " '/localhome/volodin/miniconda3/envs/neuronfailure/lib/python3.6/site-packages/IPython/extensions',\n",
       " '/localhome/volodin/.ipython',\n",
       " '/localhome/volodin/local/usr/bin']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path += ['/localhome/volodin/local/usr/bin']\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "from xvfbwrapper import Xvfb\n",
    "\n",
    "vdisplay = Xvfb()\n",
    "vdisplay.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.79109253e-19  2.85112420e-02  2.79973443e-19  3.37658751e-20\n",
      " -2.72802659e-19  1.49285011e-01 -9.97212062e-20  8.35373892e-20\n",
      "  2.46718649e-01  5.78224144e-01 -4.03739462e-19  1.01242860e-03\n",
      " -9.28486200e-20  2.26767464e-01 -1.58813677e-19 -8.97232308e-20\n",
      " -1.22145726e-19 -1.51509432e-19  1.12060673e-19 -3.48318630e-19]\n",
      "[ 2.50938945  0.          2.78354615  1.79425782 13.08579183  0.\n",
      "  0.73716363  3.35344995  0.          0.          8.93825054  0.\n",
      "  7.02955161  0.          4.71068649  3.18873635  2.06090107 10.08166738\n",
      "  3.0481157   8.53268239]\n"
     ]
    }
   ],
   "source": [
    "# https://www.cvxpy.org/\n",
    "\n",
    "# Problem data.\n",
    "m = 30\n",
    "n = 20\n",
    "np.random.seed(1)\n",
    "A = np.random.randn(m, n)\n",
    "b = np.random.randn(m)\n",
    "\n",
    "# Construct the problem.\n",
    "x = cp.Variable(n)\n",
    "objective = cp.Minimize(cp.sum_squares(A*x - b))\n",
    "constraints = [0 <= x, x <= 1]\n",
    "prob = cp.Problem(objective, constraints)\n",
    "\n",
    "# The optimal objective value is returned by `prob.solve()`.\n",
    "result = prob.solve()\n",
    "# The optimal value for x is stored in `x.value`.\n",
    "print(x.value)\n",
    "# The optimal Lagrange multiplier for a constraint is stored in\n",
    "# `constraint.dual_value`.\n",
    "print(constraints[0].dual_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "# allowing GPU memory growth to allocate only what we need\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config, graph = tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03118045, -0.0445104 , -0.02628692, -0.04654129])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "#env = wrappers.Monitor(env, 'video')\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_DIM = 4\n",
    "ACTIONS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# states\n",
    "states = tf.placeholder(tf.float64, shape = (None, S_DIM,))\n",
    "\n",
    "# taken actions\n",
    "actions = tf.placeholder(tf.int64, shape = (None,))\n",
    "\n",
    "# rewards obtained\n",
    "rewards = tf.placeholder(tf.float64, shape = (None,))\n",
    "\n",
    "# costs obtained\n",
    "costs = tf.placeholder(tf.float64, shape = (None,))\n",
    "\n",
    "# discounting factor\n",
    "gamma = tf.placeholder(tf.float64, shape = ())\n",
    "\n",
    "def fc_layer(x, n, activation = tf.nn.sigmoid):\n",
    "    \"\"\" Fully connected layer for input x and output dim n \"\"\"\n",
    "    return tf.contrib.layers.fully_connected(x, n, activation_fn=activation,\n",
    "    weights_initializer=tf.initializers.lecun_normal(), weights_regularizer=None,\n",
    "    biases_initializer=tf.zeros_initializer(), biases_regularizer=None, trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /localhome/volodin/miniconda3/envs/neuronfailure/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# layers\n",
    "with tf.name_scope('layers'):\n",
    "    z = states # state is an input\n",
    "    z = fc_layer(z, 10)\n",
    "    z# = fc_layer(z, 10)\n",
    "    #z = fc_layer(z, 10)\n",
    "    z = fc_layer(z, ACTIONS, activation = None)\n",
    "    output = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax to make probability distribution\n",
    "logits = tf.nn.softmax(output)\n",
    "\n",
    "# predicted labels\n",
    "labels = tf.argmax(logits, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to optimize the sum of rewards:\n",
    "$$\n",
    "J(\\theta)=\\mathbb{E}_{\\pi(\\theta)}\\sum\\limits_{t=0}^\\infty r_t\n",
    "$$\n",
    "\n",
    "Take the gradient and use log-likelihood trick:\n",
    "$$\n",
    "\\nabla J(\\theta)=\\mathbb{E}_{\\pi}\\sum\\limits_{t=0}^\\infty r_t\\nabla_\\theta \\log \\pi(a_t|s_t)=\\nabla_\\theta\\mathbb{E}_{\\pi}\\sum\\limits_{t=0}^\\infty r_t\\log \\pi(a_t|s_t)\n",
    "$$\n",
    "\n",
    "Therefore the task is equivalent to minimizing a loss of\n",
    "$$\n",
    "\\mathbb{E}_{\\pi}\\sum\\limits_{t=0}^\\infty r_t\\log \\pi(a_t|s_t)\n",
    "$$\n",
    "\n",
    "Which is estimated stochastically using episodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Safe algo 1: <a href=\"https://arxiv.org/pdf/1705.10528.pdf\">Constrained Policy Optimization</a>\n",
    "\n",
    "Estimating $g=\\nabla_\\theta J_r(\\pi)$ using policy gradients\n",
    "\n",
    "Estimating $b=\\nabla_\\theta J_C(\\pi)$ using policy gradients\n",
    "\n",
    "Estimating $H=\\mathbb{E}\\frac{\\partial^2}{\\partial \\theta^2}D_{KL}(\\theta'|\\theta)$\n",
    "\n",
    "Constants: $\\delta$ step size for trust region, $c=J_C-d$, where $d$ is the maximal per-episode value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dz_dw_flatten(z, params):\n",
    "    \"\"\" Calculate dz/dparams and flatten the result \"\"\"\n",
    "    return tf.concat([tf.reshape(x, shape = (-1,)) for x in tf.gradients(z, params)], axis = 0)\n",
    "\n",
    "def iterate_flatten(tensor):\n",
    "    \"\"\" Iterate over flattened items of a tensor \"\"\"\n",
    "    if type(tensor) == list:\n",
    "        for t in tensor:\n",
    "            for v in iterate_flatten(t):\n",
    "                yield v\n",
    "    elif len(tensor.shape) == 0:\n",
    "        yield tensor\n",
    "    else:\n",
    "        for idx in range(tensor.shape[0]):\n",
    "            for v in iterate_flatten(tensor[idx]):\n",
    "                yield v\n",
    "                \n",
    "def tf_hessian(var, params):\n",
    "    # gradients of the loss w.r.t. params\n",
    "    grads = tf.gradients(var, params)\n",
    "    grad_components = list(iterate_flatten(grads))\n",
    "    hessian = [dz_dw_flatten(t, params) for t in tqdm(grad_components)]\n",
    "    return hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-13-974b7e67b3ff>:23: Categorical.__init__ (from tensorflow.python.ops.distributions.categorical) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From /localhome/volodin/miniconda3/envs/neuronfailure/lib/python3.6/site-packages/tensorflow/python/ops/distributions/categorical.py:242: Distribution.__init__ (from tensorflow.python.ops.distributions.distribution) is deprecated and will be removed after 2019-01-01.\n",
      "Instructions for updating:\n",
      "The TensorFlow Distributions library has moved to TensorFlow Probability (https://github.com/tensorflow/probability). You should update all references to use `tfp.distributions` instead of `tf.distributions`.\n",
      "WARNING:tensorflow:From /localhome/volodin/miniconda3/envs/neuronfailure/lib/python3.6/site-packages/tensorflow/python/ops/array_grad.py:425: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/localhome/volodin/miniconda3/envs/neuronfailure/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/localhome/volodin/miniconda3/envs/neuronfailure/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "100%|██████████| 72/72 [00:10<00:00,  6.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# one-hot encoded actions\n",
    "a_one_hot = tf.one_hot(actions, ACTIONS)\n",
    "\n",
    "# taken logits\n",
    "#logits_taken = tf.gather(logits, actions, axis = 1)\n",
    "logits_taken = tf.boolean_mask(logits, a_one_hot)\n",
    "\n",
    "# logarithm\n",
    "log_logits = tf.log(logits_taken)\n",
    "\n",
    "# logarithm of logits * reward\n",
    "r_log_logits_sum = tf.reduce_sum(tf.multiply(rewards, log_logits))\n",
    "\n",
    "# cost return\n",
    "J_c = tf.reduce_sum(costs)\n",
    "\n",
    "# calculated loss\n",
    "loss_r = -tf.reduce_sum(tf.multiply(log_logits, tf.cumsum(rewards, reverse = True)))\n",
    "loss_c = -tf.reduce_sum(tf.multiply(log_logits, tf.cumsum(costs, reverse = True)))\n",
    "\n",
    "# KL(pi(a)||pi(a) fixed)\n",
    "kl_div_var_fixed = tf.reduce_mean(tfp.distributions.kl_divergence(\n",
    "    tf.distributions.Categorical(probs = logits),\n",
    "    tf.distributions.Categorical(probs = tf.stop_gradient(logits))))\n",
    "    #tf.distributions.Categorical(probs = logits))) #!!! not using this because want variable first parameter and fixed second\n",
    "\n",
    "# policy gradient for reward\n",
    "g = list(iterate_flatten(tf.gradients(-loss_r, params)))\n",
    "\n",
    "# policy gradient for constraint\n",
    "b = list(iterate_flatten(tf.gradients(-loss_c, params)))\n",
    "\n",
    "# hessian of KL divergence (parameter H)\n",
    "H = tf_hessian(kl_div_var_fixed, params)\n",
    "\n",
    "# flattened parameters\n",
    "theta = list(iterate_flatten(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_action(observation):\n",
    "    \"\"\" Sample an action from the policy \"\"\"\n",
    "    \n",
    "    if np.random.random() <= eps:\n",
    "        return env.action_space.sample()\n",
    "    \n",
    "    p = sess.run(logits, feed_dict = {states: [observation]})[0]\n",
    "    return np.random.choice(range(2), p = p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(obs):\n",
    "    \"\"\" Calculate scalar cost of one observation \"\"\"\n",
    "    assert isinstance(obs, np.ndarray) and obs.shape == (4,), \"Input must be an np-array [x xdot phi phidot]\"\n",
    "    \n",
    "    # parsing input\n",
    "    x, x_dot, phi, phi_dot = obs\n",
    "    \n",
    "    X_MAX = 1.0\n",
    "    X_DOT_MAX = 0.5\n",
    "    PHI_MAX = 0.1\n",
    "    PHI_DOT_MAX = 0.5\n",
    "    \n",
    "    if np.any(np.abs([x, x_dot, phi, phi_dot]) > [X_MAX, X_DOT_MAX, PHI_MAX, PHI_DOT_MAX]):\n",
    "        return 1\n",
    "    \n",
    "    # in all other cases no cost\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rollout():\n",
    "    \"\"\" Obtain rollout using policy \"\"\"\n",
    "    done = False\n",
    "    observation = env.reset()\n",
    "    sarc = []\n",
    "    while not done:\n",
    "        act = sample_action(observation)\n",
    "        observation_, reward, done, info = env.step(act) # take a random action\n",
    "        cost_ = cost(observation_)\n",
    "        global observations\n",
    "        observations += [observation_]\n",
    "        sarc.append((observation, act, reward, cost_))\n",
    "        observation = observation_\n",
    "    env.close()\n",
    "    return sarc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OwnGradientDescent():\n",
    "    def __init__(self, gamma = 0.5, theta = 0.9):\n",
    "        # gamma (learning rate)\n",
    "        self.gamma = tf.Variable(gamma, dtype = tf.float32)\n",
    "        self.theta = theta\n",
    "        \n",
    "    def minimize(self, loss, params):\n",
    "        \"\"\" Minimize some loss \"\"\"\n",
    "        def decrement_weights(W, gamma, grads):\n",
    "            \"\"\" w = w - how_much \"\"\"\n",
    "            ops = [w.assign(tf.subtract(w, tf.multiply(gamma, grad))) for w, grad in zip(W, grads)]\n",
    "            return tf.group(ops)\n",
    "        \n",
    "        # gradients of the loss w.r.t. params\n",
    "        grads = tf.gradients(loss, params)\n",
    "        \n",
    "        # perform gradient descent step\n",
    "        train_op = decrement_weights(params, self.gamma, grads)\n",
    "        \n",
    "        # updating gamma\n",
    "        upd_op = self.gamma.assign(tf.multiply(self.gamma, self.theta))\n",
    "        \n",
    "        return tf.group(train_op, upd_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/localhome/volodin/miniconda3/envs/neuronfailure/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "opt = tf.train.AdamOptimizer(0.005).minimize(loss_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one learning iteration\n",
    "#step = learning_step()\n",
    "step = opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(gamma_):\n",
    "    # obtaining rollout data\n",
    "    S, A, R, C = list(zip(*get_rollout()))\n",
    "    sess.run(step, feed_dict = {states: S, actions: A, rewards: R, costs: C, gamma: gamma_})\n",
    "    return np.sum(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "r = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# non-greediness\n",
    "eps = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 26.87it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(10)):\n",
    "    #gamma_ = (1000 - i) / 50000.\n",
    "    gamma_ = 0.05\n",
    "    r += [train_step(gamma_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_CPO(S, A, R, C, delta = 0.1, d = 50, H_lambda = 0.01):\n",
    "    # CPO hyperparameters\n",
    "\n",
    "    # D_KL maximal distance\n",
    "    #delta\n",
    "\n",
    "    # maximal constraint return\n",
    "    #d\n",
    "\n",
    "    # matrix conditioner\n",
    "    #H_lambda\n",
    "    \n",
    "    # calculating H, g, b, J from obtained data\n",
    "    H_, J_c_, b_, g_ = sess.run([H, J_c, b, g], feed_dict = {states: S, actions: A, rewards: R, costs: C})\n",
    "    \n",
    "    # converting to matrix form\n",
    "    g_ = np.array([g_]).T\n",
    "    b_ = np.array([b_]).T\n",
    "    H_ = np.array(H_) + np.eye(len(H_)) * H_lambda\n",
    "\n",
    "    # constraint dissatisfaction\n",
    "    c = J_c_ - d\n",
    "\n",
    "    # current parameters\n",
    "    theta_k = list(iterate_flatten(sess.run(params)))\n",
    "    \n",
    "    # https://www.cvxpy.org/\n",
    "\n",
    "    # Construct the problem.\n",
    "    theta = cp.Variable(72)\n",
    "    objective = cp.Maximize(g_.T @ (theta - theta_k))\n",
    "    constraints = [c + b_.T @ (theta - theta_k) <= 0, cp.quad_form(theta - theta_k, H_) <= 2 * delta]\n",
    "    prob = cp.Problem(objective, constraints)\n",
    "\n",
    "    # The optimal objective value is returned by `prob.solve()`.\n",
    "    result = prob.solve(gp=False)\n",
    "    # The optimal value for x is stored in `x.value`.\n",
    "    print(theta.value)\n",
    "    # The optimal Lagrange multiplier for a constraint is stored in\n",
    "    # `constraint.dual_value`.\n",
    "    #print(constraints[0].dual_value, constraints[1].dual_value)\n",
    "    \n",
    "    load_params(params, theta.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_params(params, vector):\n",
    "    \"\"\" Params: list of tensors, vector: array with new values (shape as flattened params) \"\"\"\n",
    "    # index to start\n",
    "    idx = 0\n",
    "    \n",
    "    # array with assign operators\n",
    "    assigns = []\n",
    "    \n",
    "    # loop over parameters\n",
    "    for p in params:\n",
    "        # length of current parameter (flattened)\n",
    "        curr_len = np.prod(p.shape)\n",
    "        \n",
    "        # new values for p\n",
    "        p_new_value = vector[idx:idx+curr_len]\n",
    "        \n",
    "        # reshaping the values\n",
    "        assigns.append(tf.assign(p, p_new_value.reshape(p.shape)))\n",
    "        \n",
    "        # incrementing start ID\n",
    "        idx += curr_len\n",
    "        \n",
    "    # all assigns in one operation\n",
    "    assigns = tf.group(assigns)\n",
    "    \n",
    "    # running the operation\n",
    "    sess.run(assigns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.5260213  -0.10875747  0.35197788  0.26378278  0.40846158  0.31948562\n",
      "  1.43602992 -0.51994258  0.03880309  0.80911927 -0.19664552 -0.58506983\n",
      " -0.33681947 -0.63787194 -0.03463686 -0.73208875 -0.43207586  0.28735122\n",
      " -0.93439039 -0.35168522 -0.49272021 -0.51425619  0.3003644   0.50199689\n",
      " -1.35361282  0.34054148 -0.91492341 -0.7878181  -0.22093869 -0.55555895\n",
      "  0.54767889  0.01578584  0.66748887  0.01259661 -0.30303579  0.05088231\n",
      " -0.40347277 -0.14404383  0.09403651 -0.48966935 -2.83779657 -0.86497546\n",
      " -2.1253072  -3.02681871  3.51305572 -3.06627353  4.20826376  2.90912974\n",
      " -2.17443829  3.93894661  0.9765633  -1.46515016 -0.29649485 -0.23517808\n",
      "  1.18946243 -0.92512621  2.02227105 -1.66429667 -3.93213645  3.13152796\n",
      "  1.76809673 -1.55149009 -3.99923354  4.25533037 -2.2847743   2.9485421\n",
      "  0.86472045 -0.89832846 -4.46043278  3.62145951 -2.84836801  2.82856041]\n"
     ]
    }
   ],
   "source": [
    "S, A, R, C = zip(*get_rollout())\n",
    "solve_CPO(S, A, R, C, delta = 0.1, d = 50, H_lambda = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "ename": "DCPError",
     "evalue": "Problem does not follow DCP rules. However, the problem does follow DGP rules. Consider calling this function with `gp=True`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDCPError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-d1bcb674d3fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# The optimal objective value is returned by `prob.solve()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m# The optimal value for x is stored in `x.value`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuronfailure/lib/python3.6/site-packages/cvxpy/problems/problem.py\u001b[0m in \u001b[0;36msolve\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0msolve_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProblem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_solve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msolve_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuronfailure/lib/python3.6/site-packages/cvxpy/problems/problem.py\u001b[0m in \u001b[0;36m_solve\u001b[0;34m(self, solver, warm_start, verbose, parallel, gp, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m                                             verbose, **kwargs)\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_chains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolving_inverse_data\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuronfailure/lib/python3.6/site-packages/cvxpy/problems/problem.py\u001b[0m in \u001b[0;36m_construct_chains\u001b[0;34m(self, solver, gp)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m     def _solve(self,\n",
      "\u001b[0;32m~/miniconda3/envs/neuronfailure/lib/python3.6/site-packages/cvxpy/problems/problem.py\u001b[0m in \u001b[0;36m_construct_chains\u001b[0;34m(self, solver, gp)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_intermediate_chain\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                     \u001b[0mconstruct_intermediate_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_solvers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_intermediate_problem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_intermediate_inverse_data\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_intermediate_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuronfailure/lib/python3.6/site-packages/cvxpy/reductions/solvers/intermediate_chain.py\u001b[0m in \u001b[0;36mconstruct_intermediate_chain\u001b[0;34m(problem, candidates, gp)\u001b[0m\n\u001b[1;32m     50\u001b[0m         append = (\" However, the problem does follow DGP rules. \"\n\u001b[1;32m     51\u001b[0m                   \"Consider calling this function with `gp=True`.\")\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mDCPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Problem does not follow DCP rules.\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mgp\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mproblem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dgp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDCPError\u001b[0m: Problem does not follow DCP rules. However, the problem does follow DGP rules. Consider calling this function with `gp=True`."
     ]
    }
   ],
   "source": [
    "# https://www.cvxpy.org/\n",
    "\n",
    "# Construct the DUAL problem (doesn't work...)\n",
    "nu = cp.Variable(1)\n",
    "lambda_ = cp.Variable(1)\n",
    "objective = cp.Maximize(-(gHg - 2 * r_ * nu + nu ** 2 * S_) + nu * c - lambda_ * delta / 2)\n",
    "constraints = [0 <= nu, 0 <= lambda_]\n",
    "prob = cp.Problem(objective, constraints)\n",
    "\n",
    "# The optimal objective value is returned by `prob.solve()`.\n",
    "result = prob.solve(gp=False)\n",
    "# The optimal value for x is stored in `x.value`.\n",
    "print(x.value)\n",
    "# The optimal Lagrange multiplier for a constraint is stored in\n",
    "# `constraint.dual_value`.\n",
    "print(constraints[0].dual_value, constraints[1].dual_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = env.unwrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.wrappers.Monitor(env, './video')\n",
    "get_rollout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./cartpole-h1.ckpt'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.Saver().save(sess, './cartpole-h1.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./cartpole-h1.ckpt\n"
     ]
    }
   ],
   "source": [
    "tf.train.Saver().restore(sess, './cartpole-h1.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
